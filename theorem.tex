\chapter{The De Moivre-Laplace theorem}

\section{Formulation of De Moivre-Laplace theorem}

\includefig[0.25\textwidth]{moivre}{Abraham de Moivre}{File \href{https://commons.wikimedia.org/wiki/File:Abraham_de_moivre.jpg}{``Abraham de moivre.jpg''} from Wikimedia Commons. Uploaded by user \href{https://commons.wikimedia.org/wiki/User:\%E7\%AB\%B9\%E9\%BA\%A6\%E9\%AD\%9A(Searobin)} Searobin and licensed under Public Domain. Original source: \url{https://www.york.ac.uk/depts/maths/histstat/people/} .}

\includefig[0.25\textwidth]{laplace}{Pierre Simon Laplace}{File \href{http://flickr.com/photos/37667416@N04/4840056407}{``Laplace''} from Flickr. Uploaded by \href{http://www.flickr.com/people/37667416@N04}{Biblioteca de la Facultad de Derecho y Ciencias del Trabajo Universidad de Sevilla} and licensed under \href{https://creativecommons.org/licenses/by/2.0/deed.en}{CC-BY 2.0}.}

In the last chapter we have seen with the application of the binomial distribution in the investigation of the sex ratio that calculations with the binomial distribution are arduous. In order to compute $\binom nk p^kq^{n-k}$ there are $n+2\min\{k,n-k\}-1$ operations necessary.

This motivates approximations to the binomial distribution to minimize the computational efforts. With those approximations also equations like $\P{\Bs \le z}=\alpha$ are easier to solver for $z$ or $n$ ($\Bs$ shall be binomially distributed). Explicit solutions for those equations are hard to calculate~\cite[p. 469]{hald1}.

The first simple approximation to the binomial distribution was found by Abraham de Moivre with the help of James Stirling~\cite[p. 469]{hald1}. His proof was later extended by Pierre Simon Laplace~\cite[pp. 495 ff.]{hald1}. Today this approximation is known as the ``De Moivre-Laplace theorem''~\cite[pp. 64-67]{irle}.

I want to split this theorem in two parts. With the first part one get an approximation for the probability mass function of a binomial distribution:

\begin{theorem}[Local version of De Moivre-Laplace theorem]
  Let $\fphi{x}=\frac{1}{\sqrt{2\pi}}\fexp{-\frac{x^2}2}$ be the density function of the standardized normal distribution~\cite[p. 48]{georgii} and $p\in(0,1)$. For $n$ large enough we have~\cite[p. 65]{irle}
  \begin{align}
    \binom nk p^k q^{n-k} \approx \frac 1{\sqrt{2\pi npq}} \fexp{-\frac{(k-np)^2}{2npq}}
  \end{align}
  or (with $\x=\frac{k-np}{\sqrt npq}$ and $h=\frac1{\sqrt{npq}}$)~\cite[p. 133]{georgii}:
  \begin{align}
    \binom nk p^k q^{n-k} \approx \fphi{\x} h
  \end{align}
\end{theorem}

In the second part one gets an approximation to the culmulative distribution function which is the actual theorem by De Moivre and Laplace:

\begin{theorem}[De Moivre-Laplace theorem]
  For any $b,a \in \R$ we have for large $n$~\cite[p. 136]{georgii}\cite[p. 67]{irle}
  \begin{align}
    \sum_{a \le \x\le b} \bb{\x} \approx \int_a^b \fphi{t} \d{t}
  \end{align}
  and
  \begin{align}
    \sum_{\x \le a} \bb{\x} \approx \fPhi{a}
  \end{align}
  with $\fPhi{a} = \int_{-\infty}^a \fphi{t} \d{t}$ being the cumulative distribution function of the standardized normal distribution~\cite[p. 134]{georgii}.
\end{theorem}

Thus the main statement of the de Moivre-Laplace theorem is that the standardized binomial distribution can be approximated with the standardized normal distribution (for large $n$).

\section{The journey to De Moivre-Laplace theorem}

In \emph{A history of propability and statistics and their applications before 1750} Anders Hald gave a good summarize how de Moivre and Laplace found their theorem. In \cite[pp. 469-470]{hald1} he wrote:

\begin{quotation}
  In 1721 de Moivre began his investigations od the binomial distribution for $p=\tfrac 12$. He first found an approximation to the maximum term and next an approximation to the ratio of the maximum to the term at a distance of $d$ from the maximum. [...] From 1725 onward James Stirling (1692-1770) worked on the same problem and found that the constant entering de Moivre's formula equals $\sqrt{2\pi}$. After having obtained these results they realized that it would be simpler to begin with an approximation to $\ln n!$, and they both proved Stirling's formula, $n! \sim \sqrt{2\pi n}n^ne^{-n}$. De Moivre's proofs are given in the \emph{Miscellanea Analytica} (MA)(1730), Stirling's in his \emph{Methodus Differentialis} (1730).

  [...] Three years later, de Moivre (1733) simplified his result for $p=\tfrac 12$ and showed that the normal density function may be used as an approcimation to the binomial. The generalization to an arbitrary value of $p$ is of course very easy, so without proof de Moivre stated that

  \begin{align*}
      b(np+d,n,p) \sim (2\pi npq)^{-\tfrac 12} \exp\left( -\frac{d^2}{2npq} \right), d = O(\sqrt n),
  \end{align*}

  and that $P_d$ [with $P_d=\P{|\Bs -np|\le d}$] may be obtained by integration. He also showd how to calculate the standardized normal probability integral [numerically] and gave the result for one, two, and three times the standard deviation.
\end{quotation}

In his book \emph{A History of Mathematical Statistics From 1750 to 1930} Hald wrote about the proof by Laplace~\cite[p. 24]{hald2}:

\begin{quotation}
  De Moivre's theorem is mentioned only occasionally in the probabilistic literature between 1740 and 1812, when Laplace (TAP, II, \$16) \todo{cite} filled the gaps in the proof. Laplace assumes that p is a real number in the unit interval \todo{foonote} and shows that the mode of the binomial distribution equals $m=[(n+1)p]=np+z$, say, $-q < z \le p$. By means of Stirling's formula he obtains an expansion of $\ln(m+d)$ in powers of $d$ including terms of order $n^{-1/2}$, so that he gets a correction to the main term depending on $(q-p)d/npq$, a correction of skewness as it is called today. He notes, that the approximation may be improved by taking more terms of the expansion into account.
\end{quotation}

\section{The error in the theorem}

In the above section we have gotten to know the theorem by de Moivre-Laplace in a qulitative version without an estimate of the approximation error. The global version of de Moivre-Laplace with an error estimation provides the Berry-Esseen theorem. It states~\cite[70-71]{nourdin}\cite{wiki:berry}:

\begin{theorem}[The Berry-Esseen theorem]
  Let $\seq{X_n}$ be i.i.d. random variables with $\E{X_k}=\mu$ and $\E{(X_k-\mu)^2}=\sigma^2$. Let $Y_n = \frac 1{\sqrt{n}\sigma} \sum_{k=0}^n \br{X_k-\mu}$ be the standardized sum of the first $n$ random variables $X_k$. Let $\rho = \E{\abs{X_k-\mu}^3} < \infty$. Then there is a $C>0$ independent of $n$ and $x$ such that

  \begin{align}
    \abs{\P{Y_n \le x} - \fPhi{x}} \le \frac{C \rho}{\sqrt n \sigma^3}
  \end{align}
\end{theorem}

As we have already seen in the above section, $\BBs$ is the standardized sum of $n$ i.i.d. Binomial trials $\seq{X_n}$. $X_n$ has the two possible outcomes $1$ and $0$ whereby $1$ has the possibility $p$ and $0$ has the possibility $q=1-p$ \cite[p. 32]{georgii}\cite{wiki:bernoulli_distribution}. We have $\E{X_k} = \mu = p$ and $\E{(X_k-p)^2}=\sigma^2=pq$ \cite{wiki:bernoulli_distribution}\cite[p. 112]{georgii}. For $\rho$ we get
\begin{align}
  \E{\abs{X_k-p}^3} &= p q^3 + q p^3 = pq (p^2+q^2)
\end{align}
Thus we can follow from the Berry-Esseen theorem, that there is a $C>0$ with
\begin{align}
  \sup_{x\in\R} \abs{\P{\BBs \le x}-\fPhi{x}} \le \frac{C(p^2+q^2)}{\sqrt{npq}}
\end{align}

We see that $\P{\BBs \le x}$ converges uniformly in $x$ to $\fPhi{x}$ with an error of order $\bigo{\frac 1{\sqrt{n}}}=\bigo{h}$. Because $\P{a\le \BBs \le b} = \P{\BBs \le b} - \P{\BBs < a}$ we can easily show, that also $\P{a \le \BBs \le b}$ converges uniformly in $x$ to $\fPhi{a}-\fPhi{b}$ with an error of the same convergence speed $\bigo{\frac 1{\sqrt{n}}}=\bigo{h}$.

\newcommand*{\Cmaxbin}{0.4215}
Currently the estimate $\Cmin \le C \le \Cmax$ is proven (see \cite{shevtsova2011} and \cite{esseen1956}). For the special case of the binomial distribution we can make the estimate $C \le \Cmaxbin$~\cite{nagaev}\cite{muaddib}.

\section{Application}

Graunt + sex ratio, Computerprogramme
