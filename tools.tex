\chapter{Tools for this thesis} \label{chapter:tools}

In this chapter I will introduce and explain the tools necessary for the upcoming proofs. To keep this chapter short I will prove all following theorems in the appendix.

\section{The big Psi notation}

\subsection{Definition of the big Psi notation}
An important part of this thesis is dedicated to estimate the quality of the normal approximation for the binomial distribution. Therefore we will investigate the error of the cumulative distribution function between the normal and the binomial distribution.

To describe the asymptotic behavior of an error, the big O notation can be used. It declares the convergence speed with which the error converges at least to zero. Given an error $\epsilon_n$ for the $n$-th step of an approximation the big O notation $\epsilon_n \in \bigo{a_n}$ means~\cite[p.~444]{graham}\cite[p.~100]{aigner}

\begin{align} \label{bigo_def1}
  \seq{\epsilon_n} \in \bigo{a_n} :\iff \exists C > 0\, \exists N\in\N\,\forall n\ge N: \abs{\epsilon_n} \le C \cdot \abs{a_n}
\end{align}

\noindent This definition is equivalent to~\cite[p.~383]{hachenberger}\cite{wiki:bigo}

\begin{align} \label{bigo_def_limsup}
  \seq{\epsilon_n} \in \bigo{a_n} :\iff \exists C_\infty > 0: \limsup_{n\to\infty} \abs{\frac{\epsilon_n}{a_n}} \le C_\infty
\end{align}

So $\epsilon_n \in \bigo{\frac 1n}$ means that $\epsilon_n$ approaches zero at least with the convergence speed as $\seq{\frac 1n}$. Thereby the advantage of the big O notation are its simple arithmetic rules. For example we have

\begin{align}
  \bigo{\frac 1n} + \bigo{\frac 1{n^2}} \subseteq \bigo{\frac 1n}
\end{align}

These arithmetic rules simplify error estimations. Unfortunately the big O notation does only provide an estimate of the convergence speed but no estimation of the error's value since the constants $C$ and $C_\infty$ in \eqref{bigo_def1} and \eqref{bigo_def_limsup} are not known\footnote{cf.~\cite[p.~444]{graham},~\cite{hurkyl_bigo} and \cite{templatetypedef_bigo}}.

Therefore I want to introduce the big Psi notation with which besides to the convergence speed also an estimate for the asymptotic error can be stated. The big Psi notation is defined as\footnote{Although it is likely that this notation is already used in mathematical literature I could not find a reference for it, cf.~\cite{tampis_bigpsi}}:

\begin{definition}[Big Psi notation]
  Let $\seq{a_n}$ be a sequence with $a_n > 0$ for all $n\in\N$. $\bigpsi{a_n}$ is the set of all sequences $\seq{\epsilon_n}$ fulfilling $\limsup_{n\to\infty} \abs{\frac{\epsilon_n}{a_n}} \le 1$. Thus

  \begin{align}
    \seq{\epsilon_n} \in \bigpsi{a_n} :\iff \limsup_{n\to\infty} \abs{\frac{\epsilon_n}{a_n}} \le 1
  \end{align}

  \todo{Notation with $\epsilon_n$ instead of $\seq{\epsilon_n}$?! Explanation for $\epsilon_n \in \bigo{a_n}$ necessary?}
\end{definition}

Note that the definition of the big Psi notation is the same as the limes superior definition \eqref{bigo_def_limsup} of the big O notation whereby $C_\infty$ has the concrete value $1$. Thus we directly see

\begin{align}
  \seq{\epsilon_n} \in \bigpsi{a_n} \implies \seq{\epsilon_n} \in \bigo{a_n}
\end{align}

\noindent Due to the properties of the limes superior we may also define the big Psi notation as\footnote{This definition has the advantage that it also allows $a_n=0$ for any $n\in\N$.}

\todo{Is here a proof necessary?}

\begin{align}
  \seq{\epsilon_n} \in \bigpsi{a_n} \iff \forall \epsilon > 0\, \exists N \in \N\, \forall n\ge N: \abs{\epsilon_n} \le (1+\epsilon)\abs{a_n}
\end{align}

So $\seq{\epsilon_n}\in\bigpsi{a_n}$ iff for each $\epsilon > 0$ almost all $\abs{\epsilon_n}$ are less then or equal $(1+\epsilon)\abs{a_n}$. Because an estimation is only stated for almost all $n\in\N$ the big Psi notation provides an upper bound for the asymptotic error.

Note that $\epsilon_n\in\bigpsi{a_n}$ does not imply $\abs{\epsilon_n}\le\abs{a_n}$ for any $n\in\N$. Take for example $\epsilon_n = \frac 1n + \frac 1{n^2}$. We have $\epsilon_n \in \bigpsi{\frac 1n}$ although $\epsilon_n > \frac 1n$ for all $n\in\N$\footnote{Proof for $\seq{\epsilon_n} \in \bigpsi{\frac 1n}$: $\limsup_{n\to\infty} \frac{\frac 1n + \frac 1{n^2}}{\frac 1n} = \limsup_{n\to\infty} \left(1+\frac 1n\right) = 1 \le 1$}.

\subsection{The little-o notation}

We will also use the little-o notation which is defined as~\cite[pp.~99,~103]{aigner}\cite[p.~385]{hachenberger}\cite{wiki:bigo}

\begin{definition}
  Let $\seq{a_n}$ be a sequence with $a_n > 0$ for all $n\in\N$\footnote{To allow $a_n=0$ it is also possible to define the little-notation via~\cite[pp.~448]{graham}\cite{wiki:bigo}

  \begin{align}
    \seq{\epsilon_n}\in\littleo{a_n} :\iff \forall \epsilon > 0\, \exists N\in\N\, \forall n \ge N: \abs{\epsilon_n} \le \epsilon \abs{a_n}
  \end{align}

  \noindent In this work we will only deal with sequences $\seq{a_n}$ with $a_n > 0$ for all $n\in\N$.
}. $\littleo{a_n}$ is the set of all sequences $\seq{\epsilon_n}$ with $\lim_{n\to\infty} \abs{\frac{\epsilon_n}{a_n}} = 0$. Thus

  \begin{align}
    \seq{\epsilon_n}\in\littleo{a_n} \iff \lim_{n\to\infty} \abs{\frac{\epsilon_n}{a_n}} = 0
  \end{align}
\end{definition}

\subsection{Arithmetic rules}

The big Psi notation shares with the big O notation a set of easy arithmetic rules. For example we have\footnote{With the rules proved in theorem \ref{thm:bigpsi:rules} this statement can be shown in the following way:

  \begin{align}
    \bigpsi{\frac an}+\bigpsi{\frac{b}{n^2}} & \subseteq \bigpsi{\frac an} + \bigo{\frac b{n^2}} \nl
    & \begin{comment}
      \frac b{n^2} \in \littleo{\frac an}
    \end{comment} \nl
    & \subseteq \bigpsi{\frac an} + \littleo{\frac an} \nl
    & \subseteq \bigpsi{\frac an}
  \end{align}
}

\begin{align} \label{bigpsi_rule_example}
  \bigpsi{\frac an}+\bigpsi{\frac b{n^2}} \subseteq \bigpsi{\frac an}
\end{align}

That's the reason why we will use the big Psi notation in this thesis. If we would estimate the error $\epsilon_n$ for each $n\in\N$ and not its limit behavior, we could not neglect the term $\bigpsi{\frac b{n^2}}$ in the above equation \eqref{bigpsi_rule_example}. Thus the error term would become more complicated. We also cannot apply simplifications which are only true for almost all $n\in\N$ (and false for finitely many $n\in\N$). This is the reason why I will only consider the asymptotic error in this thesis.

The following theorem contains all arithmetic rules for the big Psi notation which we will use in this thesis. You will find a proof in the appendix.

\input{bigpsi_rules}

\section{Interval arithmetic}

\subsection{Additive interval definition}

In this thesis we will need to derive besides to an approximation for the binomial distribution also an estimate for the error of this approximation. Therefore we will use the interval arithmetic\footnote{A good introduction into the field of interval analysis gives Ramon E. Moore in his book ``Interval analysis''\cite{moore}. The Wikipedia article ``Interval arithmetic''\cite{wikipedia:interval_arithmetic} also gives a good overview.} because it allows an error propagation calculation alongside the derivation of the approximation.

The main idea of interval arithmetic is to replace numbers in a calculation with intervals. These intervals represent the range where one can be sure to find the considered number. Whereas interval arithmetic often deals with intervals of the form $[a,b]$ defined by their lower and upper bounds\footnote{For example \cite[p.~5~ff.]{moore}, \cite[p.~9~ff.]{moore:methods}, \cite[p. 84 ff.]{kulisch} and \cite{wikipedia:interval_arithmetic}.} we will use the notation $\an{a}$ which is defined as\footnote{This notation is similar to the form (2.26) in \cite[p. 14]{moore:methods}. I also defined such a notation in my bachelor thesis \cite[p. 19]{kulla}.}

\begin{definition}
  The interval $\an{a}$ for $\epsilon \in \Rplus$ and $a\in \R$ is defined as $[a-\epsilon,a+\epsilon]$.
\end{definition}

So $\an{a}$ represents a number $x$ which is approximated by $a$ with an absolute error $\abs{x-a}$ less then or equal $\epsilon$~\cite[p.~5]{moore:methods}. One purpose of interval arithmetic is to offer arithmetic rules to calculate with intervals such as~\cite[pp.~19-20]{kulla}

\begin{align}
  \an{a}+\an[\delta]{b} = \an[\epsilon+\delta]{a+b}
\end{align}

These rules are defined in a way, that the resulting interval is a superset of all possible outcomes of the operation. Let $f:D\subseteq\R^n\to\R$ be an $n$-ary operation of real numbers and let $\an[\epsilon_1]{a_1},\ldots,\an[\epsilon_2]{a_2}$ be $n$ intervals, then the result  $f\left(\an[\epsilon_1]{a_1},\ldots,\an[\epsilon_n]{a_n}\right)$ of the operation with all $n$ intervals is defined in a way that\footnote{cf. theorem 3.1 in \cite[p. 21]{moore:methods}} \todo{Paragraph verbessern}

\begin{align}
  \left\{f(x_1,\ldots,x_n):x_1\in\an[\epsilon_1]{a_1},\ldots,x_2\in\an[\epsilon_n]{a_n}\right\} \subseteq f\left(\an[\epsilon_1]{a_1},\ldots,\an[\epsilon_n]{a_n}\right)
\end{align}

Because we cannot know which number $x_k \in \an[\epsilon_k]{a_k}$ is the actual number of the $k$th interval, each number of $\left\{f(x_1,\ldots,x_n):x_1\in\an[\epsilon_1]{a_1},\ldots,x_2\in\an[\epsilon_n]{a_n}\right\}$ can be the actual result of the operation. Thus we have to take a superset of this image as a result. Obviously the final result shall be an interval and as small as possible, too. The arithmetic rules we will use for this thesis are (cf.~\cite[pp.~19-24.]{kulla})

\begin{theorem}

\end{theorem}

\subsection{Multiplicative interval definition}

The multiplicative rule for intervals defined as $\an{a}$ is not simple~\cite[p.~22]{kulla}:

\begin{align}
  \an[\epsilon]{a} \cdot \an[\delta]{b} \subseteq \an[\abs{a}\delta+\abs{b}\epsilon+\epsilon\delta]{a\cdot b}
\end{align}

Because we will often have to deal with products I introduce a slightly different definition of an interval\footnote{It is likely that this kind of interval definition is already used in mathematical literature. Unfortunately I could not find a reference for it, cf.~\cite{tampis:ean}.}

\begin{definition}
  The interval $\ean{a}$ for $\epsilon,a\in\Rplus$ is defined as $\left[a\cdot e^{-\epsilon},a\cdot e^\epsilon\right]$.
\end{definition}

\noindent This interval definition has the advantage its rule for products is easy: \todo{footnote with ref to proof}

\begin{align}
  \ean[\epsilon]{a}\cdot \ean[\delta]{b} = \ean[\epsilon+\delta]{a+b}
\end{align}

\noindent In the following chapters we will use the following arithmetic rules:

\begin{theorem}

\end{theorem}

\subsection{Interval arithmetic and the big Psi notation}

\section{Finite difference calculus}

\todo{wirklich notwendig?!}
